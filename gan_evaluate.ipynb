{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from scipy.stats import bernoulli\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import (T5ForConditionalGeneration,\n",
    "                          T5Tokenizer)\n",
    "from datasets import Dataset\n",
    "\n",
    "device = torch.device(\"cuda:1\")\n",
    "random.seed(42)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS     = 2\n",
    "\n",
    "def sample_disparity(col, race, tau):\n",
    "    race = race.apply(lambda x: 1 if x=='WHITE' else -1)*tau\n",
    "    temp = col+race\n",
    "    temp = temp.apply(lambda x: 1 if x>1 else 0 if x<0 else x)\n",
    "    return bernoulli.rvs(temp)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.hidden_layer1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.hidden_layer2 = nn.Sequential(\n",
    "            nn.Linear(128, 32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.hidden_layer3 = nn.Sequential(\n",
    "            nn.Linear(32, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        output = self.hidden_layer1(x)\n",
    "        output = self.hidden_layer2(output)\n",
    "        output = self.hidden_layer3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/preprocessed.csv', lineterminator='\\n')\n",
    "df = df.sort_values(by=['SUBJECT_ID','HADM_ID','CHARTDATE'])\\\n",
    "                .groupby(['SUBJECT_ID','HADM_ID'])\\\n",
    "                .head(1)\n",
    "df = df[['SUBJECT_ID','ETHNICITY','DIAGNOSIS','TEXT','apsiii']].reset_index(drop=True)\n",
    "df['apsiii_norm'] = (df['apsiii']-min(df['apsiii']))/(max(df['apsiii'])-min(df['apsiii']))\n",
    "df['actual_treatment'] = bernoulli.rvs(df['apsiii_norm'])\n",
    "df['given_treatment'] = sample_disparity(df['apsiii_norm'], df['ETHNICITY'], 0.1)\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "dataset_train = Dataset.from_pandas(df_train, split='train')\n",
    "dataset_test  = Dataset.from_pandas(df_test,  split='test')\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataloader_test  = DataLoader(dataset_test,  batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(examples, tokenizer):\n",
    "    inputs = examples['TEXT']  \n",
    "    labels = nn.functional.one_hot(examples['given_treatment'], \n",
    "                                   num_classes=2)\n",
    "    tokenized_inputs = tokenizer(inputs,\n",
    "                                 return_tensors='pt',\n",
    "                                 max_length=512,\n",
    "                                 truncation=True,\n",
    "                                 padding=True)\n",
    "    model_inputs = {}\n",
    "    model_inputs['input_ids']      = tokenized_inputs['input_ids']\n",
    "    model_inputs['attention_mask'] = tokenized_inputs['attention_mask']\n",
    "    return model_inputs, labels.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load debiased GAN, only keep the encoder\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"results/gan/model-0-2000\")\n",
    "model_enc = model.encoder\n",
    "del model\n",
    "model_enc.to(device)\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\",\n",
    "                                            output_scores=True,\n",
    "                                            output_hidden_states=True,\n",
    "                                            model_max_length=512)\n",
    "# Define the models and optimizer\n",
    "classifier = Classifier(input_dim=512, output_dim=2).to(device)\n",
    "classifier_optimizer = AdamW(classifier.parameters(), \n",
    "                          lr=5e-3)\n",
    "\n",
    "# Define loss\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(batch, labels):\n",
    "    classifier.train()\n",
    "    classifier_optimizer.zero_grad()\n",
    "    \n",
    "    x = model_enc(**batch)                                       # Get embeddings from encoder\n",
    "    x = x.last_hidden_state.sum(axis=1).detach()                 # Sum across emb_dim, detach\n",
    "\n",
    "    pred = classifier(x)                                         # Make prediction\n",
    "    loss = criterion(pred, labels)\n",
    "    loss.backward()\n",
    "    classifier_optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def eval_classifier(batch, labels):\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        x = model_enc(**batch)                                       # Get embeddings from encoder\n",
    "        x = x.last_hidden_state.sum(axis=1).detach()                 # Sum across emb_dim, detach\n",
    "\n",
    "        pred = classifier(x)                                         # Make prediction\n",
    "        loss = criterion(pred, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ep):\n",
    "    train_loss, test_loss, steps = 0, 0, 0\n",
    "    for batch in dataloader_train:\n",
    "        steps += 1\n",
    "        batch, labels           = encode(batch, tokenizer)           # Tokenize and obtain labels\n",
    "        batch['input_ids']      = batch['input_ids'].to(device)      # Send to GPU\n",
    "        batch['attention_mask'] = batch['attention_mask'].to(device)\n",
    "        labels                  = labels.to(device)\n",
    "        train_loss += train_classifier(batch, labels)\n",
    "        if steps % 500 == 0:\n",
    "            torch.save(classifier.state_dict(), f\"results/gan/classifier-{ep}-{steps}\")\n",
    "\n",
    "    for batch in dataloader_test:\n",
    "        batch, labels           = encode(batch, tokenizer)           # Tokenize and obtain labels\n",
    "        batch['input_ids']      = batch['input_ids'].to(device)      # Send to GPU\n",
    "        batch['attention_mask'] = batch['attention_mask'].to(device)\n",
    "        labels                  = labels.to(device)\n",
    "        test_loss += eval_classifier(batch, labels)\n",
    "    \n",
    "    train_loss /= len(dataloader_train)\n",
    "    test_loss  /= len(dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in range(EPOCHS):\n",
    "    train(ep)\n",
    "    torch.save(classifier.state_dict(), f\"results/gan/classifier-{ep}-final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: Batch 0\n",
      "Predicting: Batch 1\n",
      "Predicting: Batch 2\n",
      "Predicting: Batch 3\n",
      "Predicting: Batch 4\n",
      "Predicting: Batch 5\n",
      "Predicting: Batch 6\n",
      "Predicting: Batch 7\n",
      "Predicting: Batch 8\n",
      "Predicting: Batch 9\n",
      "Predicting: Batch 10\n",
      "Predicting: Batch 11\n",
      "Predicting: Batch 12\n",
      "Predicting: Batch 13\n",
      "Predicting: Batch 14\n",
      "Predicting: Batch 15\n",
      "Predicting: Batch 16\n",
      "Predicting: Batch 17\n",
      "Predicting: Batch 18\n",
      "Predicting: Batch 19\n",
      "Predicting: Batch 20\n",
      "Predicting: Batch 21\n",
      "Predicting: Batch 22\n",
      "Predicting: Batch 23\n",
      "Predicting: Batch 24\n",
      "Predicting: Batch 25\n",
      "Predicting: Batch 26\n",
      "Predicting: Batch 27\n",
      "Predicting: Batch 28\n",
      "Predicting: Batch 29\n",
      "Predicting: Batch 30\n",
      "Predicting: Batch 31\n",
      "Predicting: Batch 32\n",
      "Predicting: Batch 33\n",
      "Predicting: Batch 34\n",
      "Predicting: Batch 35\n",
      "Predicting: Batch 36\n",
      "Predicting: Batch 37\n",
      "Predicting: Batch 38\n",
      "Predicting: Batch 39\n",
      "Predicting: Batch 40\n",
      "Predicting: Batch 41\n",
      "Predicting: Batch 42\n",
      "Predicting: Batch 43\n",
      "Predicting: Batch 44\n",
      "Predicting: Batch 45\n",
      "Predicting: Batch 46\n",
      "Predicting: Batch 47\n",
      "Predicting: Batch 48\n",
      "Predicting: Batch 49\n",
      "Predicting: Batch 50\n",
      "Predicting: Batch 51\n",
      "Predicting: Batch 52\n",
      "Predicting: Batch 53\n",
      "Predicting: Batch 54\n",
      "Predicting: Batch 55\n",
      "Predicting: Batch 56\n",
      "Predicting: Batch 57\n",
      "Predicting: Batch 58\n",
      "Predicting: Batch 59\n",
      "Predicting: Batch 60\n",
      "Predicting: Batch 61\n",
      "Predicting: Batch 62\n",
      "Predicting: Batch 63\n",
      "Predicting: Batch 64\n",
      "Predicting: Batch 65\n",
      "Predicting: Batch 66\n",
      "Predicting: Batch 67\n",
      "Predicting: Batch 68\n",
      "Predicting: Batch 69\n",
      "Predicting: Batch 70\n",
      "Predicting: Batch 71\n",
      "Predicting: Batch 72\n",
      "Predicting: Batch 73\n",
      "Predicting: Batch 74\n",
      "Predicting: Batch 75\n",
      "Predicting: Batch 76\n",
      "Predicting: Batch 77\n",
      "Predicting: Batch 78\n",
      "Predicting: Batch 79\n",
      "Predicting: Batch 80\n",
      "Predicting: Batch 81\n",
      "Predicting: Batch 82\n",
      "Predicting: Batch 83\n",
      "Predicting: Batch 84\n",
      "Predicting: Batch 85\n",
      "Predicting: Batch 86\n",
      "Predicting: Batch 87\n",
      "Predicting: Batch 88\n",
      "Predicting: Batch 89\n",
      "Predicting: Batch 90\n",
      "Predicting: Batch 91\n",
      "Predicting: Batch 92\n",
      "Predicting: Batch 93\n",
      "Predicting: Batch 94\n",
      "Predicting: Batch 95\n",
      "Predicting: Batch 96\n",
      "Predicting: Batch 97\n",
      "Predicting: Batch 98\n",
      "Predicting: Batch 99\n",
      "Predicting: Batch 100\n",
      "Predicting: Batch 101\n",
      "Predicting: Batch 102\n",
      "Predicting: Batch 103\n",
      "Predicting: Batch 104\n",
      "Predicting: Batch 105\n",
      "Predicting: Batch 106\n",
      "Predicting: Batch 107\n",
      "Predicting: Batch 108\n",
      "Predicting: Batch 109\n",
      "Predicting: Batch 110\n",
      "Predicting: Batch 111\n",
      "Predicting: Batch 112\n",
      "Predicting: Batch 113\n",
      "Predicting: Batch 114\n",
      "Predicting: Batch 115\n",
      "Predicting: Batch 116\n",
      "Predicting: Batch 117\n",
      "Predicting: Batch 118\n",
      "Predicting: Batch 119\n",
      "Predicting: Batch 120\n",
      "Predicting: Batch 121\n",
      "Predicting: Batch 122\n",
      "Predicting: Batch 123\n",
      "Predicting: Batch 124\n",
      "Predicting: Batch 125\n",
      "Predicting: Batch 126\n",
      "Predicting: Batch 127\n",
      "Predicting: Batch 128\n",
      "Predicting: Batch 129\n",
      "Predicting: Batch 130\n",
      "Predicting: Batch 131\n",
      "Predicting: Batch 132\n",
      "Predicting: Batch 133\n",
      "Predicting: Batch 134\n",
      "Predicting: Batch 135\n",
      "Predicting: Batch 136\n",
      "Predicting: Batch 137\n",
      "Predicting: Batch 138\n",
      "Predicting: Batch 139\n",
      "Predicting: Batch 140\n",
      "Predicting: Batch 141\n",
      "Predicting: Batch 142\n",
      "Predicting: Batch 143\n",
      "Predicting: Batch 144\n",
      "Predicting: Batch 145\n",
      "Predicting: Batch 146\n",
      "Predicting: Batch 147\n",
      "Predicting: Batch 148\n",
      "Predicting: Batch 149\n",
      "Predicting: Batch 150\n",
      "Predicting: Batch 151\n",
      "Predicting: Batch 152\n",
      "Predicting: Batch 153\n",
      "Predicting: Batch 154\n",
      "Predicting: Batch 155\n",
      "Predicting: Batch 156\n",
      "Predicting: Batch 157\n",
      "Predicting: Batch 158\n",
      "Predicting: Batch 159\n",
      "Predicting: Batch 160\n",
      "Predicting: Batch 161\n",
      "Predicting: Batch 162\n",
      "Predicting: Batch 163\n",
      "Predicting: Batch 164\n",
      "Predicting: Batch 165\n",
      "Predicting: Batch 166\n",
      "Predicting: Batch 167\n",
      "Predicting: Batch 168\n",
      "Predicting: Batch 169\n",
      "Predicting: Batch 170\n",
      "Predicting: Batch 171\n",
      "Predicting: Batch 172\n",
      "Predicting: Batch 173\n",
      "Predicting: Batch 174\n",
      "Predicting: Batch 175\n",
      "Predicting: Batch 176\n",
      "Predicting: Batch 177\n",
      "Predicting: Batch 178\n",
      "Predicting: Batch 179\n",
      "Predicting: Batch 180\n",
      "Predicting: Batch 181\n",
      "Predicting: Batch 182\n",
      "Predicting: Batch 183\n",
      "Predicting: Batch 184\n",
      "Predicting: Batch 185\n",
      "Predicting: Batch 186\n",
      "Predicting: Batch 187\n",
      "Predicting: Batch 188\n",
      "Predicting: Batch 189\n",
      "Predicting: Batch 190\n",
      "Predicting: Batch 191\n",
      "Predicting: Batch 192\n",
      "Predicting: Batch 193\n",
      "Predicting: Batch 194\n",
      "Predicting: Batch 195\n",
      "Predicting: Batch 196\n",
      "Predicting: Batch 197\n",
      "Predicting: Batch 198\n",
      "Predicting: Batch 199\n",
      "Predicting: Batch 200\n",
      "Predicting: Batch 201\n",
      "Predicting: Batch 202\n",
      "Predicting: Batch 203\n",
      "Predicting: Batch 204\n",
      "Predicting: Batch 205\n",
      "Predicting: Batch 206\n",
      "Predicting: Batch 207\n",
      "Predicting: Batch 208\n",
      "Predicting: Batch 209\n",
      "Predicting: Batch 210\n",
      "Predicting: Batch 211\n",
      "Predicting: Batch 212\n",
      "Predicting: Batch 213\n",
      "Predicting: Batch 214\n",
      "Predicting: Batch 215\n",
      "Predicting: Batch 216\n",
      "Predicting: Batch 217\n",
      "Predicting: Batch 218\n",
      "Predicting: Batch 219\n",
      "Predicting: Batch 220\n",
      "Predicting: Batch 221\n",
      "Predicting: Batch 222\n",
      "Predicting: Batch 223\n",
      "Predicting: Batch 224\n",
      "Predicting: Batch 225\n",
      "Predicting: Batch 226\n",
      "Predicting: Batch 227\n",
      "Predicting: Batch 228\n",
      "Predicting: Batch 229\n",
      "Predicting: Batch 230\n",
      "Predicting: Batch 231\n",
      "Predicting: Batch 232\n",
      "Predicting: Batch 233\n",
      "Predicting: Batch 234\n",
      "Predicting: Batch 235\n",
      "Predicting: Batch 236\n",
      "Predicting: Batch 237\n",
      "Predicting: Batch 238\n",
      "Predicting: Batch 239\n",
      "Predicting: Batch 240\n",
      "Predicting: Batch 241\n",
      "Predicting: Batch 242\n",
      "Predicting: Batch 243\n",
      "Predicting: Batch 244\n",
      "Predicting: Batch 245\n",
      "Predicting: Batch 246\n",
      "Predicting: Batch 247\n",
      "Predicting: Batch 248\n",
      "Predicting: Batch 249\n",
      "Predicting: Batch 250\n",
      "Predicting: Batch 251\n",
      "Predicting: Batch 252\n",
      "Predicting: Batch 253\n",
      "Predicting: Batch 254\n",
      "Predicting: Batch 255\n",
      "Predicting: Batch 256\n",
      "Predicting: Batch 257\n",
      "Predicting: Batch 258\n",
      "Predicting: Batch 259\n",
      "Predicting: Batch 260\n",
      "Predicting: Batch 261\n",
      "Predicting: Batch 262\n",
      "Predicting: Batch 263\n",
      "Predicting: Batch 264\n",
      "Predicting: Batch 265\n",
      "Predicting: Batch 266\n",
      "Predicting: Batch 267\n",
      "Predicting: Batch 268\n",
      "Predicting: Batch 269\n",
      "Predicting: Batch 270\n",
      "Predicting: Batch 271\n",
      "Predicting: Batch 272\n",
      "Predicting: Batch 273\n",
      "Predicting: Batch 274\n",
      "Predicting: Batch 275\n",
      "Predicting: Batch 276\n",
      "Predicting: Batch 277\n",
      "Predicting: Batch 278\n",
      "Predicting: Batch 279\n",
      "Predicting: Batch 280\n",
      "Predicting: Batch 281\n",
      "Predicting: Batch 282\n",
      "Predicting: Batch 283\n",
      "Predicting: Batch 284\n",
      "Predicting: Batch 285\n",
      "Predicting: Batch 286\n",
      "Predicting: Batch 287\n",
      "Predicting: Batch 288\n",
      "Predicting: Batch 289\n",
      "Predicting: Batch 290\n",
      "Predicting: Batch 291\n",
      "Predicting: Batch 292\n",
      "Predicting: Batch 293\n",
      "Predicting: Batch 294\n",
      "Predicting: Batch 295\n",
      "Predicting: Batch 296\n",
      "Predicting: Batch 297\n",
      "Predicting: Batch 298\n",
      "Predicting: Batch 299\n",
      "Predicting: Batch 300\n",
      "Predicting: Batch 301\n",
      "Predicting: Batch 302\n",
      "Predicting: Batch 303\n",
      "Predicting: Batch 304\n",
      "Predicting: Batch 305\n",
      "Predicting: Batch 306\n",
      "Predicting: Batch 307\n",
      "Predicting: Batch 308\n",
      "Predicting: Batch 309\n",
      "Predicting: Batch 310\n",
      "Predicting: Batch 311\n",
      "Predicting: Batch 312\n",
      "Predicting: Batch 313\n",
      "Predicting: Batch 314\n",
      "Predicting: Batch 315\n",
      "Predicting: Batch 316\n",
      "Predicting: Batch 317\n",
      "Predicting: Batch 318\n",
      "Predicting: Batch 319\n",
      "Predicting: Batch 320\n",
      "Predicting: Batch 321\n",
      "Predicting: Batch 322\n",
      "Predicting: Batch 323\n",
      "Predicting: Batch 324\n",
      "Predicting: Batch 325\n",
      "Predicting: Batch 326\n",
      "Predicting: Batch 327\n",
      "Predicting: Batch 328\n",
      "Predicting: Batch 329\n",
      "Predicting: Batch 330\n",
      "Predicting: Batch 331\n",
      "Predicting: Batch 332\n",
      "Predicting: Batch 333\n",
      "Predicting: Batch 334\n",
      "Predicting: Batch 335\n",
      "Predicting: Batch 336\n",
      "Predicting: Batch 337\n",
      "Predicting: Batch 338\n",
      "Predicting: Batch 339\n",
      "Predicting: Batch 340\n",
      "Predicting: Batch 341\n",
      "Predicting: Batch 342\n",
      "Predicting: Batch 343\n",
      "Predicting: Batch 344\n",
      "Predicting: Batch 345\n",
      "Predicting: Batch 346\n",
      "Predicting: Batch 347\n",
      "Predicting: Batch 348\n",
      "Predicting: Batch 349\n",
      "Predicting: Batch 350\n",
      "Predicting: Batch 351\n",
      "Predicting: Batch 352\n",
      "Predicting: Batch 353\n",
      "Predicting: Batch 354\n",
      "Predicting: Batch 355\n",
      "Predicting: Batch 356\n",
      "Predicting: Batch 357\n",
      "Predicting: Batch 358\n",
      "Predicting: Batch 359\n",
      "Predicting: Batch 360\n",
      "Predicting: Batch 361\n",
      "Predicting: Batch 362\n",
      "Predicting: Batch 363\n",
      "Predicting: Batch 364\n",
      "Predicting: Batch 365\n",
      "Predicting: Batch 366\n",
      "Predicting: Batch 367\n",
      "Predicting: Batch 368\n",
      "Predicting: Batch 369\n",
      "Predicting: Batch 370\n",
      "Predicting: Batch 371\n",
      "Predicting: Batch 372\n",
      "Predicting: Batch 373\n",
      "Predicting: Batch 374\n",
      "Predicting: Batch 375\n",
      "Predicting: Batch 376\n",
      "Predicting: Batch 377\n",
      "Predicting: Batch 378\n",
      "Predicting: Batch 379\n",
      "Predicting: Batch 380\n",
      "Predicting: Batch 381\n",
      "Predicting: Batch 382\n",
      "Predicting: Batch 383\n",
      "Predicting: Batch 384\n",
      "Predicting: Batch 385\n",
      "Predicting: Batch 386\n",
      "Predicting: Batch 387\n",
      "Predicting: Batch 388\n",
      "Predicting: Batch 389\n",
      "Predicting: Batch 390\n",
      "Predicting: Batch 391\n",
      "Predicting: Batch 392\n",
      "Predicting: Batch 393\n",
      "Predicting: Batch 394\n",
      "Predicting: Batch 395\n",
      "Predicting: Batch 396\n",
      "Predicting: Batch 397\n",
      "Predicting: Batch 398\n",
      "Predicting: Batch 399\n",
      "Predicting: Batch 400\n",
      "Predicting: Batch 401\n",
      "Predicting: Batch 402\n",
      "Predicting: Batch 403\n",
      "Predicting: Batch 404\n",
      "Predicting: Batch 405\n",
      "Predicting: Batch 406\n",
      "Predicting: Batch 407\n",
      "Predicting: Batch 408\n",
      "Predicting: Batch 409\n",
      "Predicting: Batch 410\n",
      "Predicting: Batch 411\n",
      "Predicting: Batch 412\n",
      "Predicting: Batch 413\n",
      "Predicting: Batch 414\n",
      "Predicting: Batch 415\n",
      "Predicting: Batch 416\n",
      "Predicting: Batch 417\n",
      "Predicting: Batch 418\n",
      "Predicting: Batch 419\n",
      "Predicting: Batch 420\n",
      "Predicting: Batch 421\n",
      "Predicting: Batch 422\n",
      "Predicting: Batch 423\n",
      "Predicting: Batch 424\n",
      "Predicting: Batch 425\n",
      "Predicting: Batch 426\n",
      "Predicting: Batch 427\n",
      "Predicting: Batch 428\n",
      "Predicting: Batch 429\n",
      "Predicting: Batch 430\n",
      "Predicting: Batch 431\n",
      "Predicting: Batch 432\n",
      "Predicting: Batch 433\n",
      "Predicting: Batch 434\n",
      "Predicting: Batch 435\n"
     ]
    }
   ],
   "source": [
    "race_lst, actual_lst, pred_lst, apsiii_lst = [], [], [], []\n",
    "for idx, batch in enumerate(dataloader_test):\n",
    "    print(f\"Predicting: Batch {idx}\")\n",
    "    \n",
    "    # Obtain actual treatment and race features\n",
    "    actual_treatment        = nn.functional.one_hot(batch['actual_treatment'], \n",
    "                                                    num_classes=2).float()\n",
    "    race                    = torch.tensor(list(map(lambda x: 1*(x=='BLACK'), \n",
    "                                                    batch['ETHNICITY'])))\n",
    "    batch, labels           = encode(batch, tokenizer)           # Tokenize and obtain labels\n",
    "    batch['input_ids']      = batch['input_ids'].to(device)      # Send to GPU\n",
    "    batch['attention_mask'] = batch['attention_mask'].to(device)\n",
    "    labels                  = labels.to(device)\n",
    "    \n",
    "    x = model_enc(**batch)                                       # Get embeddings from encoder\n",
    "    x = x.last_hidden_state.sum(axis=1).detach()                 # Sum across emb_dim, detach\n",
    "    pred = classifier(x).cpu().detach()                          # Make prediction\n",
    "    \n",
    "    race_lst.append(race)\n",
    "    actual_lst.append(actual_treatment)\n",
    "    pred_lst.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_lst   = torch.concat(race_lst)\n",
    "actual_lst = torch.concat(actual_lst)\n",
    "pred_lst   = torch.concat(pred_lst) \n",
    "apsiii_lst = torch.concat(apsiii_lst)\n",
    "\n",
    "idx_0 = torch.where(race_lst==0)[0]\n",
    "idx_1 = torch.where(race_lst==1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7847)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(1.0*(actual_lst[idx_0].argmax(dim=1)==pred_lst[idx_0].argmax(dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7581)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(1.0*(actual_lst[idx_1].argmax(dim=1)==pred_lst[idx_1].argmax(dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4956999550579042"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true  = actual_lst[idx_0].numpy(),\n",
    "              y_score = pred_lst[idx_0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5349819342123786"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true  = actual_lst[idx_1].numpy(),\n",
    "              y_score = pred_lst[idx_1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        ...,\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = pd.DataFrame({'race':race_lst.numpy(),\n",
    "              'actual':np.argmax(actual_lst.numpy(), axis=1),\n",
    "              'pred_not_prescribe':pred_lst[:,0].numpy(),\n",
    "              'pred_prescribe':pred_lst[:,1].numpy(),\n",
    "              'apsiii':apsiii_lst.numpy()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis['prescribe'] = 1*(df_analysis['pred_prescribe'] > df_analysis['pred_not_prescribe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis['correct'] = 1*(df_analysis['prescribe']==df_analysis['actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Black): 0.789 (95 patients), Accuracy (White): 0.788 (688 patients)\n",
      "Accuracy (Black): 0.729 (376 patients), Accuracy (White): 0.782 (2580 patients)\n",
      "Accuracy (Black): 0.78 (246 patients), Accuracy (White): 0.786 (1966 patients)\n",
      "Accuracy (Black): 0.787 (75 patients), Accuracy (White): 0.794 (617 patients)\n",
      "Accuracy (Black): 0.759 (29 patients), Accuracy (White): 0.768 (198 patients)\n",
      "Accuracy (Black): 0.833 (12 patients), Accuracy (White): 0.778 (63 patients)\n",
      "Accuracy (Black): 0.5 (2 patients), Accuracy (White): 0.783 (23 patients)\n",
      "Accuracy (Black): 0.5 (2 patients), Accuracy (White): 0.778 (9 patients)\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    if i<=5:\n",
    "        temp = df_analysis.loc[(df_analysis.apsiii >= 20*i)&\\\n",
    "                            (df_analysis.apsiii < 20*(i+1))]\\\n",
    "                                .groupby('race')\\\n",
    "                                .aggregate({'correct':'mean', 'prescribe':'mean', 'apsiii':'count'})\n",
    "    else:\n",
    "        temp = df_analysis.loc[(df_analysis.apsiii >= 20*i)]\\\n",
    "                                .groupby('race')\\\n",
    "                                .aggregate({'correct':'mean', 'prescribe':'mean', 'apsiii':'count'})\n",
    "    print(f\"Accuracy (Black): {round(temp['correct'][1],3)} ({temp['apsiii'][1]} patients), Accuracy (White): {round(temp['correct'][0],3)} ({temp['apsiii'][0]} patients)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d78cf5354c54536ee2fe2974b55665bb4fd5d446126f0c5d0792c4750b1da66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
