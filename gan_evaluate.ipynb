{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import bernoulli\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import percentileofscore\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import (T5ForConditionalGeneration,\n",
    "                          T5Tokenizer)\n",
    "from datasets import Dataset\n",
    "\n",
    "device = torch.device(\"cuda:1\")\n",
    "random.seed(42)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS     = 10\n",
    "TAU        = 0.0\n",
    "DIAG_PROP  = 0.8\n",
    "\n",
    "def sample_disparity(actual_treatment, race, tau, diag_prop):\n",
    "    race = race.apply(lambda x: 0 if x=='WHITE' else 1)\n",
    "    bias = race*actual_treatment*tau\n",
    "    prob = actual_treatment.apply(lambda x: x*diag_prop) - bias\n",
    "    # temp = temp.apply(lambda x: 1 if x>1 else 0 if x<0 else x)\n",
    "    return bernoulli.rvs(prob)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.hidden_layer1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.hidden_layer2 = nn.Sequential(\n",
    "            nn.Linear(128, 32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.hidden_layer3 = nn.Sequential(\n",
    "            nn.Linear(32, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        output = self.hidden_layer1(x)\n",
    "        output = self.hidden_layer2(output)\n",
    "        output = self.hidden_layer3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/preprocessed.csv', lineterminator='\\n')\n",
    "df = df.sort_values(by=['SUBJECT_ID','HADM_ID','CHARTDATE'])\\\n",
    "                .groupby(['SUBJECT_ID','HADM_ID'])\\\n",
    "                .head(1)\n",
    "                \n",
    "idx_white = random.sample(list(df.loc[df.ETHNICITY=='WHITE'].index), \n",
    "              df.loc[df.ETHNICITY=='BLACK'].shape[0])\n",
    "df = pd.concat([df.loc[idx_white], \n",
    "                df.loc[df.ETHNICITY=='BLACK']]).reset_index(drop=True)\n",
    "\n",
    "df = df[['SUBJECT_ID','ETHNICITY','DIAGNOSIS','TEXT','apsiii']].reset_index(drop=True)\n",
    "# df['apsiii_norm'] = (df['apsiii']-min(df['apsiii']))/(max(df['apsiii'])-min(df['apsiii']))\n",
    "df['apsiii_norm'] = list(map(lambda x: percentileofscore(df['apsiii'], x, 'mean')/100, \n",
    "                            df['apsiii']))\n",
    "df['actual_treatment'] = bernoulli.rvs(df['apsiii_norm'])\n",
    "df['given_treatment'] = sample_disparity(df['actual_treatment'], df['ETHNICITY'], TAU, DIAG_PROP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train, _ = RandomOverSampler(random_state=42).fit_resample(df_train, df_train['given_treatment'])\n",
    "df_test, _ =  RandomOverSampler(random_state=42).fit_resample(df_test,  df_test['given_treatment'])\n",
    "\n",
    "dataset_train = Dataset.from_pandas(df_train, split='train')\n",
    "dataset_test  = Dataset.from_pandas(df_test,  split='test')\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataloader_test  = DataLoader(dataset_test,  batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Treatment: 0.4972369053339741, Given Treatment: 0.39968765016818836\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>given_treatment</th>\n",
       "      <th>prop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>actual_treatment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">BLACK</th>\n",
       "      <th>0</th>\n",
       "      <td>2065</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2097</td>\n",
       "      <td>1682</td>\n",
       "      <td>0.802098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">WHITE</th>\n",
       "      <th>0</th>\n",
       "      <td>2120</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2042</td>\n",
       "      <td>1645</td>\n",
       "      <td>0.805583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            SUBJECT_ID  given_treatment      prop\n",
       "ETHNICITY actual_treatment                                       \n",
       "BLACK     0                       2065                0  0.000000\n",
       "          1                       2097             1682  0.802098\n",
       "WHITE     0                       2120                0  0.000000\n",
       "          1                       2042             1645  0.805583"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats = df.groupby(['ETHNICITY','actual_treatment']).aggregate({'SUBJECT_ID':'count',\n",
    "                                                        'given_treatment':'sum'})\n",
    "df_stats['prop'] = df_stats['given_treatment']/df_stats['SUBJECT_ID']\n",
    "print(f\"Actual Treatment: {np.mean(df['actual_treatment'])}, Given Treatment: {np.mean(df['given_treatment'])}\")\n",
    "df_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(examples, tokenizer):\n",
    "    inputs = examples['TEXT']  \n",
    "    labels = nn.functional.one_hot(examples['given_treatment'], \n",
    "                                   num_classes=2)\n",
    "    tokenized_inputs = tokenizer(inputs,\n",
    "                                 return_tensors='pt',\n",
    "                                 max_length=512,\n",
    "                                 truncation=True,\n",
    "                                 padding=True)\n",
    "    model_inputs = {}\n",
    "    model_inputs['input_ids']      = tokenized_inputs['input_ids']\n",
    "    model_inputs['attention_mask'] = tokenized_inputs['attention_mask']\n",
    "    return model_inputs, labels.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load debiased GAN, only keep the encoder\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"results/gan/model-1-final\")\n",
    "model_enc = model.encoder\n",
    "del model\n",
    "model_enc.to(device)\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\",\n",
    "                                            output_scores=True,\n",
    "                                            output_hidden_states=True,\n",
    "                                            model_max_length=512)\n",
    "# Define the models and optimizer\n",
    "classifier = Classifier(input_dim=512, output_dim=2).to(device)\n",
    "classifier_optimizer = AdamW(classifier.parameters(), \n",
    "                          lr=5e-3)\n",
    "\n",
    "# Define loss\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(batch, labels):\n",
    "    classifier.train()\n",
    "    classifier_optimizer.zero_grad()\n",
    "    \n",
    "    x = model_enc(**batch)                                       # Get embeddings from encoder\n",
    "    x = x.last_hidden_state.sum(axis=1).detach()                 # Sum across emb_dim, detach\n",
    "\n",
    "    pred = classifier(x)                                         # Make prediction\n",
    "    loss = criterion(pred, labels)\n",
    "    loss.backward()\n",
    "    classifier_optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def eval_classifier(batch, labels):\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        x = model_enc(**batch)                                       # Get embeddings from encoder\n",
    "        x = x.last_hidden_state.sum(axis=1).detach()                 # Sum across emb_dim, detach\n",
    "\n",
    "        pred = classifier(x)                                         # Make prediction\n",
    "        loss = criterion(pred, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ep):\n",
    "    train_loss, test_loss, steps = 0, 0, 0\n",
    "    for batch in dataloader_train:\n",
    "        steps += 1\n",
    "        batch, labels           = encode(batch, tokenizer)           # Tokenize and obtain labels\n",
    "        batch['input_ids']      = batch['input_ids'].to(device)      # Send to GPU\n",
    "        batch['attention_mask'] = batch['attention_mask'].to(device)\n",
    "        labels                  = labels.to(device)\n",
    "        train_loss += float(train_classifier(batch, labels).detach().cpu())\n",
    "        # if steps % 500 == 0:\n",
    "        #     torch.save(classifier.state_dict(), f\"results/gan/classifier-{ep}-{steps}-{TAU}-{DIAG_PROP}\")\n",
    "\n",
    "    for batch in dataloader_test:\n",
    "        batch, labels           = encode(batch, tokenizer)           # Tokenize and obtain labels\n",
    "        batch['input_ids']      = batch['input_ids'].to(device)      # Send to GPU\n",
    "        batch['attention_mask'] = batch['attention_mask'].to(device)\n",
    "        labels                  = labels.to(device)\n",
    "        test_loss += float(eval_classifier(batch, labels).detach().cpu())\n",
    "    \n",
    "    train_loss /= len(dataloader_train)\n",
    "    test_loss  /= len(dataloader_test)\n",
    "    print(f\"Epoch {ep}: {train_loss}, {test_loss}\")\n",
    "    return train_loss, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.7336700940467268, 0.6799268079554941\n",
      "Epoch 1: 0.6885591240293051, 0.7273455196478236\n",
      "Epoch 2: 0.6992151338651956, 0.7373737711606063\n",
      "Epoch 3: 0.6902955365946972, 0.6746184586539982\n",
      "Epoch 4: 0.6940793058120582, 0.7025298823521832\n",
      "Epoch 5: 0.7068158060791023, 0.791305778533455\n",
      "Epoch 6: 0.6874252450633719, 0.7867463446977571\n",
      "Epoch 7: 0.6893449221030775, 0.6731536571435103\n",
      "Epoch 8: 0.6954991177741783, 0.7164139583354859\n",
      "Epoch 9: 0.6942660197555779, 0.7003768654320184\n"
     ]
    }
   ],
   "source": [
    "best_test = np.inf\n",
    "for ep in range(EPOCHS):\n",
    "    train_loss, test_loss = train(ep)\n",
    "    if test_loss < best_test:\n",
    "        best_test = test_loss\n",
    "        torch.save(classifier.state_dict(), f\"results/gan/classifier-{TAU}-{DIAG_PROP}-final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction/Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "PNEUMONIA_KEYS = ['PNEUMONIA','PMEUMONIA','PNEUMOMIA',\n",
    "                  'PNEUMONI','PNAUMONIA','PNEMONIA',\n",
    "                  'PNEUMNOIA','PNEUMONIN','PNEUMONNIA']\n",
    "FEVER_KEYS = ['FEVER','FEER']\n",
    "\n",
    "df_filter = df.loc[df['DIAGNOSIS'].apply(lambda s: any([k in s for k in PNEUMONIA_KEYS]))]\n",
    "# df_filter = df.loc[df['DIAGNOSIS'].apply(lambda s: any([k in s for k in FEVER_KEYS]))]\n",
    "\n",
    "dataset_filter  = Dataset.from_pandas(df_filter,  split='filter')\n",
    "dataloader_filter = DataLoader(dataset_filter, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White: 0.6415094137191772 (Acc) 0.5572335513659099 ROC-AUC, Black: 0.6107784509658813 (Acc) 0.5957313245448839 ROC-AUC\n"
     ]
    }
   ],
   "source": [
    "race_lst, actual_lst, pred_lst, apsiii_lst = [], [], [], []\n",
    "for idx, batch in enumerate(dataloader_filter):\n",
    "    # print(f\"Predicting: Batch {idx}\")\n",
    "    \n",
    "    # Obtain actual treatment and race features\n",
    "    actual_treatment        = nn.functional.one_hot(batch['actual_treatment'], \n",
    "                                                    num_classes=2).float()\n",
    "    race                    = torch.tensor(list(map(lambda x: 1*(x=='BLACK'), \n",
    "                                                    batch['ETHNICITY'])))\n",
    "    apsiii = batch['apsiii']\n",
    "    \n",
    "    batch, labels           = encode(batch, tokenizer)           # Tokenize and obtain labels\n",
    "    batch['input_ids']      = batch['input_ids'].to(device)      # Send to GPU\n",
    "    batch['attention_mask'] = batch['attention_mask'].to(device)\n",
    "    labels                  = labels.to(device)\n",
    "    \n",
    "    x = model_enc(**batch)                                       # Get embeddings from encoder\n",
    "    x = x.last_hidden_state.sum(axis=1).detach()                 # Sum across emb_dim, detach\n",
    "    pred = classifier(x).cpu().detach()                          # Make prediction\n",
    "    \n",
    "    race_lst.append(race)\n",
    "    actual_lst.append(actual_treatment)\n",
    "    pred_lst.append(pred)\n",
    "    apsiii_lst.append(apsiii)\n",
    "\n",
    "race_lst   = torch.concat(race_lst)\n",
    "actual_lst = torch.concat(actual_lst)\n",
    "pred_lst   = torch.concat(pred_lst) \n",
    "apsiii_lst = torch.concat(apsiii_lst)\n",
    "\n",
    "idx_0 = torch.where(race_lst==0)[0]\n",
    "idx_1 = torch.where(race_lst==1)[0]\n",
    "\n",
    "acc_1 = float(torch.mean(1.0*(actual_lst[idx_1].argmax(dim=1)==pred_lst[idx_1].argmax(dim=1))))\n",
    "acc_0 = float(torch.mean(1.0*(actual_lst[idx_0].argmax(dim=1)==pred_lst[idx_0].argmax(dim=1))))\n",
    "roc_0 = roc_auc_score(y_true  = actual_lst[idx_0].numpy(),\n",
    "              y_score = pred_lst[idx_0].numpy())\n",
    "roc_1 = roc_auc_score(y_true  = actual_lst[idx_1].numpy(),\n",
    "              y_score = pred_lst[idx_1].numpy())\n",
    "print(f\"White: {acc_0} (Acc) {roc_0} ROC-AUC, Black: {acc_1} (Acc) {roc_1} ROC-AUC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>actual</th>\n",
       "      <th>pred_not_prescribe</th>\n",
       "      <th>pred_prescribe</th>\n",
       "      <th>apsiii</th>\n",
       "      <th>prescribe</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.402421</td>\n",
       "      <td>0.597613</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.372129</td>\n",
       "      <td>0.627998</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333899</td>\n",
       "      <td>0.666083</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.597312</td>\n",
       "      <td>0.402755</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.355063</td>\n",
       "      <td>0.645152</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.275927</td>\n",
       "      <td>0.724148</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323179</td>\n",
       "      <td>0.676949</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.411530</td>\n",
       "      <td>0.588668</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364907</td>\n",
       "      <td>0.635409</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.369346</td>\n",
       "      <td>0.630671</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     race  actual  pred_not_prescribe  pred_prescribe  apsiii  prescribe  \\\n",
       "0       0       1            0.402421        0.597613      39          1   \n",
       "1       1       1            0.372129        0.627998     122          1   \n",
       "2       1       1            0.333899        0.666083      28          1   \n",
       "3       1       1            0.597312        0.402755      59          0   \n",
       "4       0       1            0.355063        0.645152      38          1   \n",
       "..    ...     ...                 ...             ...     ...        ...   \n",
       "321     1       0            0.275927        0.724148      30          1   \n",
       "322     0       0            0.323179        0.676949      40          1   \n",
       "323     0       0            0.411530        0.588668      35          1   \n",
       "324     1       1            0.364907        0.635409      84          1   \n",
       "325     1       1            0.369346        0.630671      50          1   \n",
       "\n",
       "     correct  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          0  \n",
       "4          1  \n",
       "..       ...  \n",
       "321        0  \n",
       "322        0  \n",
       "323        0  \n",
       "324        1  \n",
       "325        1  \n",
       "\n",
       "[326 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Black): 33.333 (33.333% prescribed, 3 patients), \t Accuracy (White): 50.0 (50.0% prescribed, 2 patients)\n",
      "Accuracy (Black): 42.593 (72.222% prescribed, 54 patients), \t Accuracy (White): 50.0 (73.684% prescribed, 38 patients)\n",
      "Accuracy (Black): 70.0 (74.286% prescribed, 70 patients), \t Accuracy (White): 62.857 (82.857% prescribed, 70 patients)\n",
      "Accuracy (Black): 65.217 (69.565% prescribed, 23 patients), \t Accuracy (White): 70.968 (74.194% prescribed, 31 patients)\n",
      "Accuracy (Black): 76.923 (69.231% prescribed, 13 patients), \t Accuracy (White): 83.333 (83.333% prescribed, 12 patients)\n",
      "Accuracy (Black): 100.0 (100.0% prescribed, 1 patients), \t Accuracy (White): 100.0 (100.0% prescribed, 5 patients)\n",
      "Accuracy (Black): 100.0 (100.0% prescribed, 3 patients), \t Accuracy (White): 100.0 (100.0% prescribed, 1 patients)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3621\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3622\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4816/3670014717.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                 \u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'race'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                 \u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'correct'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prescribe'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'apsiii'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy (Black): {round(100*temp['correct'][1],3)} ({round(100*temp['prescribe'][1],3)}% prescribed, {temp['apsiii'][1]} patients), \\t Accuracy (White): {round(100*temp['correct'][0],3)} ({round(100*temp['prescribe'][0],3)}% prescribed, {temp['apsiii'][0]} patients)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3622\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3623\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3624\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3625\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "df_analysis = pd.DataFrame({'race':race_lst.numpy(),\n",
    "              'actual':np.argmax(actual_lst.numpy(), axis=1),\n",
    "              'pred_not_prescribe':pred_lst[:,0].numpy(),\n",
    "              'pred_prescribe':pred_lst[:,1].numpy(),\n",
    "              'apsiii':apsiii_lst.numpy()})\n",
    "df_analysis['prescribe'] = 1*(df_analysis['pred_prescribe'] > df_analysis['pred_not_prescribe'])\n",
    "df_analysis['correct'] = 1*(df_analysis['prescribe']==df_analysis['actual'])\n",
    "\n",
    "for i in range(8):\n",
    "    if i<=5:\n",
    "        temp = df_analysis.loc[(df_analysis.apsiii >= 20*i)&\\\n",
    "                            (df_analysis.apsiii < 20*(i+1))]\\\n",
    "                                .groupby('race')\\\n",
    "                                .aggregate({'correct':'mean', 'prescribe':'mean', 'apsiii':'count'})\n",
    "    else:\n",
    "        temp = df_analysis.loc[(df_analysis.apsiii >= 20*i)]\\\n",
    "                                .groupby('race')\\\n",
    "                                .aggregate({'correct':'mean', 'prescribe':'mean', 'apsiii':'count'})\n",
    "    print(f\"Accuracy (Black): {round(100*temp['correct'][1],3)} ({round(100*temp['prescribe'][1],3)}% prescribed, {temp['apsiii'][1]} patients), \\t Accuracy (White): {round(100*temp['correct'][0],3)} ({round(100*temp['prescribe'][0],3)}% prescribed, {temp['apsiii'][0]} patients)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d78cf5354c54536ee2fe2974b55665bb4fd5d446126f0c5d0792c4750b1da66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
